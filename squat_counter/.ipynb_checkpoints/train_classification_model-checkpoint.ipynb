{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intended-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "governmental-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/all/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efficient-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>leftShoulder_x</th>\n",
       "      <th>rightShoulder_x</th>\n",
       "      <th>leftElbow_x</th>\n",
       "      <th>rightElbow_x</th>\n",
       "      <th>leftWrist_x</th>\n",
       "      <th>rightWrist_x</th>\n",
       "      <th>leftHip_x</th>\n",
       "      <th>rightHip_x</th>\n",
       "      <th>leftKnee_x</th>\n",
       "      <th>...</th>\n",
       "      <th>leftElbow_y</th>\n",
       "      <th>rightElbow_y</th>\n",
       "      <th>leftWrist_y</th>\n",
       "      <th>rightWrist_y</th>\n",
       "      <th>leftHip_y</th>\n",
       "      <th>rightHip_y</th>\n",
       "      <th>leftKnee_y</th>\n",
       "      <th>rightKnee_y</th>\n",
       "      <th>leftAnkle_y</th>\n",
       "      <th>rightAnkle_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028879</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>-0.208539</td>\n",
       "      <td>0.133494</td>\n",
       "      <td>0.553482</td>\n",
       "      <td>0.544736</td>\n",
       "      <td>-0.553482</td>\n",
       "      <td>-0.516662</td>\n",
       "      <td>-0.049678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562358</td>\n",
       "      <td>-0.456403</td>\n",
       "      <td>-0.418759</td>\n",
       "      <td>-0.340103</td>\n",
       "      <td>-0.173011</td>\n",
       "      <td>-0.135185</td>\n",
       "      <td>0.172529</td>\n",
       "      <td>0.215667</td>\n",
       "      <td>0.81501</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>-0.208216</td>\n",
       "      <td>0.127405</td>\n",
       "      <td>0.551929</td>\n",
       "      <td>0.538002</td>\n",
       "      <td>-0.551929</td>\n",
       "      <td>-0.520010</td>\n",
       "      <td>-0.039873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556598</td>\n",
       "      <td>-0.456695</td>\n",
       "      <td>-0.416286</td>\n",
       "      <td>-0.337262</td>\n",
       "      <td>-0.165655</td>\n",
       "      <td>-0.127346</td>\n",
       "      <td>0.171157</td>\n",
       "      <td>0.214671</td>\n",
       "      <td>0.81628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021715</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>-0.200171</td>\n",
       "      <td>0.139674</td>\n",
       "      <td>0.558486</td>\n",
       "      <td>0.545609</td>\n",
       "      <td>-0.558486</td>\n",
       "      <td>-0.524005</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.548266</td>\n",
       "      <td>-0.450706</td>\n",
       "      <td>-0.408890</td>\n",
       "      <td>-0.328410</td>\n",
       "      <td>-0.156467</td>\n",
       "      <td>-0.116489</td>\n",
       "      <td>0.166829</td>\n",
       "      <td>0.208025</td>\n",
       "      <td>0.81339</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.102587</td>\n",
       "      <td>-0.455513</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.377385</td>\n",
       "      <td>0.600181</td>\n",
       "      <td>-0.600181</td>\n",
       "      <td>-0.488323</td>\n",
       "      <td>-0.255987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.493919</td>\n",
       "      <td>-0.456069</td>\n",
       "      <td>-0.384128</td>\n",
       "      <td>-0.321206</td>\n",
       "      <td>-0.044052</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.201063</td>\n",
       "      <td>0.214102</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.981365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.099820</td>\n",
       "      <td>-0.447694</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>0.384425</td>\n",
       "      <td>0.594730</td>\n",
       "      <td>-0.594730</td>\n",
       "      <td>-0.490453</td>\n",
       "      <td>-0.244410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496747</td>\n",
       "      <td>-0.454576</td>\n",
       "      <td>-0.381820</td>\n",
       "      <td>-0.320757</td>\n",
       "      <td>-0.038753</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>0.198652</td>\n",
       "      <td>0.209723</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.981767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   position  leftShoulder_x  rightShoulder_x  leftElbow_x  rightElbow_x  \\\n",
       "0       0.0        0.028879         0.004747    -0.208539      0.133494   \n",
       "1       0.0        0.024693         0.005102    -0.208216      0.127405   \n",
       "2       0.0        0.021715         0.010279    -0.200171      0.139674   \n",
       "3       0.0        0.096159         0.102587    -0.455513      0.014135   \n",
       "4       0.0        0.106783         0.099820    -0.447694      0.007295   \n",
       "\n",
       "   leftWrist_x  rightWrist_x  leftHip_x  rightHip_x  leftKnee_x  ...  \\\n",
       "0     0.553482      0.544736  -0.553482   -0.516662   -0.049678  ...   \n",
       "1     0.551929      0.538002  -0.551929   -0.520010   -0.039873  ...   \n",
       "2     0.558486      0.545609  -0.558486   -0.524005   -0.034736  ...   \n",
       "3     0.377385      0.600181  -0.600181   -0.488323   -0.255987  ...   \n",
       "4     0.384425      0.594730  -0.594730   -0.490453   -0.244410  ...   \n",
       "\n",
       "   leftElbow_y  rightElbow_y  leftWrist_y  rightWrist_y  leftHip_y  \\\n",
       "0    -0.562358     -0.456403    -0.418759     -0.340103  -0.173011   \n",
       "1    -0.556598     -0.456695    -0.416286     -0.337262  -0.165655   \n",
       "2    -0.548266     -0.450706    -0.408890     -0.328410  -0.156467   \n",
       "3    -0.493919     -0.456069    -0.384128     -0.321206  -0.044052   \n",
       "4    -0.496747     -0.454576    -0.381820     -0.320757  -0.038753   \n",
       "\n",
       "   rightHip_y  leftKnee_y  rightKnee_y  leftAnkle_y  rightAnkle_y  \n",
       "0   -0.135185    0.172529     0.215667      0.81501      1.000000  \n",
       "1   -0.127346    0.171157     0.214671      0.81628      1.000000  \n",
       "2   -0.116489    0.166829     0.208025      0.81339      1.000000  \n",
       "3    0.005164    0.201063     0.214102      1.00000      0.981365  \n",
       "4    0.008812    0.198652     0.209723      1.00000      0.981767  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "julian-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = list(data.columns.values)\n",
    "properties.remove('position')\n",
    "\n",
    "X = data[properties]\n",
    "y = data['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unknown-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='position', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-chain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-coffee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quarterly-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artificial-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stylish-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(x, units):\n",
    "    x = Dense(units)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unsigned-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(24,))\n",
    "\n",
    "x = block(input, 256)\n",
    "x = block(x, 1024)\n",
    "x = block(x, 2048)\n",
    "x = block(x, 2048)\n",
    "x = block(x, 1024)\n",
    "x = block(x, 256)\n",
    "\n",
    "x = Dense(units = 1)(x)\n",
    "output = Activation('sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "million-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model (inputs=input, outputs =output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crazy-bangladesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               6400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,952,577\n",
      "Trainable params: 8,939,265\n",
      "Non-trainable params: 13,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "absent-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "early-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "186/186 [==============================] - 3s 7ms/step - loss: 0.6932 - accuracy: 0.4764\n",
      "Epoch 2/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6899 - accuracy: 0.5944\n",
      "Epoch 3/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6842 - accuracy: 0.6417\n",
      "Epoch 4/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.6872 - accuracy: 0.5730\n",
      "Epoch 5/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6766 - accuracy: 0.6569\n",
      "Epoch 6/100\n",
      "186/186 [==============================] - 1s 8ms/step - loss: 0.6798 - accuracy: 0.6125\n",
      "Epoch 7/100\n",
      "186/186 [==============================] - 1s 7ms/step - loss: 0.6845 - accuracy: 0.5745\n",
      "Epoch 8/100\n",
      " 37/186 [====>.........................] - ETA: 1s - loss: 0.6690 - accuracy: 0.6585"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b52d1e24076d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hothi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-dimension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "choice-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "378/378 [==============================] - 2s 2ms/step - loss: 1.2803 - accuracy: 0.6293\n",
      "Epoch 2/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.6952 - accuracy: 0.6757\n",
      "Epoch 3/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7585\n",
      "Epoch 4/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.7398\n",
      "Epoch 5/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.8092\n",
      "Epoch 6/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7831\n",
      "Epoch 7/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7894\n",
      "Epoch 8/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.8024\n",
      "Epoch 9/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7623\n",
      "Epoch 10/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5157 - accuracy: 0.8115\n",
      "Epoch 11/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5063 - accuracy: 0.8228\n",
      "Epoch 12/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7915\n",
      "Epoch 13/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7452\n",
      "Epoch 14/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.7912\n",
      "Epoch 15/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7975\n",
      "Epoch 16/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7839\n",
      "Epoch 17/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.8014\n",
      "Epoch 18/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7813\n",
      "Epoch 19/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7977\n",
      "Epoch 20/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7890\n",
      "Epoch 21/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.8243\n",
      "Epoch 22/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7716\n",
      "Epoch 23/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8112\n",
      "Epoch 24/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4930 - accuracy: 0.7856\n",
      "Epoch 25/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4702 - accuracy: 0.8099\n",
      "Epoch 26/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7590\n",
      "Epoch 27/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7732\n",
      "Epoch 28/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8133\n",
      "Epoch 29/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8011\n",
      "Epoch 30/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.8471\n",
      "Epoch 31/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8072\n",
      "Epoch 32/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.8153\n",
      "Epoch 33/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7805\n",
      "Epoch 34/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7589\n",
      "Epoch 35/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.8134\n",
      "Epoch 36/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4171 - accuracy: 0.8463\n",
      "Epoch 37/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8510\n",
      "Epoch 38/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.8403\n",
      "Epoch 39/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.8092\n",
      "Epoch 40/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8465\n",
      "Epoch 41/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.8371\n",
      "Epoch 42/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.8114\n",
      "Epoch 43/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8134\n",
      "Epoch 44/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.8017\n",
      "Epoch 45/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.8029\n",
      "Epoch 46/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7605\n",
      "Epoch 47/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8253\n",
      "Epoch 48/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.5193 - accuracy: 0.7966\n",
      "Epoch 49/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4299 - accuracy: 0.8217\n",
      "Epoch 50/50\n",
      "378/378 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8188\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8272\n",
      "Test accuracy: 0.8271604776382446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "df = pd.read_csv('molecular_activity.csv')\n",
    "properties = list(df.columns.values)\n",
    "properties.remove('Activity')\n",
    "X = df[properties]\n",
    "y = df['Activity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(4,)),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.asarray(X_train).astype('float32'), y_train, epochs=50, batch_size=1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-winning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-capability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-technique",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-tiger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
